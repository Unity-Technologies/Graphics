#pragma only_renderers d3d11 playstation xboxone xboxseries vulkan metal switch

// Depth related kernels
#pragma kernel ConvertObliqueDepth
#pragma kernel DownscaleDepth

// Render clouds
#pragma kernel RenderClouds

// Trace to intermedaite
#pragma kernel ReprojectClouds                      REPROJECT_CLOUDS=ReprojectClouds
#pragma kernel ReprojectCloudsRejection             REPROJECT_CLOUDS=ReprojectCloudsRejection WITH_REJECTION
#pragma kernel PreUpscaleClouds
#pragma kernel PreUpscaleCloudsSky

// Intermediate to Full resolution
#pragma kernel UpscaleAndCombineClouds_ColorRW      UPSAMPLE_KERNEL=UpscaleAndCombineClouds_ColorRW CAN_RW_ON_COLOR_BUFFER
#pragma kernel UpscaleAndCombineClouds_ColorCopy    UPSAMPLE_KERNEL=UpscaleAndCombineClouds_ColorCopy
#pragma kernel UpscaleAndCombineCloudsSky           UPSAMPLE_KERNEL_SKY=UpscaleAndCombineCloudsSky

// Full resolution combination
#pragma kernel CombineClouds_ColorRW                COMBINE_KERNEL=CombineClouds_ColorRW CAN_RW_ON_COLOR_BUFFER
#pragma kernel CombineClouds_ColorCopy              COMBINE_KERNEL=CombineClouds_ColorCopy
#pragma kernel CombineCloudsSky                     COMBINE_KERNEL_SKY=CombineCloudsSky

// Shadows
#pragma kernel ComputeVolumetricCloudsShadow
#pragma kernel FilterVolumetricCloudsShadow

#pragma multi_compile _ PHYSICALLY_BASED_SUN
#pragma multi_compile _ LOCAL_VOLUMETRIC_CLOUDS
#pragma multi_compile _ USE_INTERMEDIATE_BUFFER

#if !defined(LOCAL_VOLUMETRIC_CLOUDS)
    #define DISTANT_VOLUMETRIC_CLOUDS
#endif

//#define WITHOUT_LDS
// #pragma enable_d3d11_debug_symbols

// The number of octaves for the multi-scattering
#define NUM_MULTI_SCATTERING_OCTAVES 2
// Global offset to the high frequency noise
#define CLOUD_DETAIL_MIP_OFFSET 0.0
// Global offset for reaching the LUT/AO
#define CLOUD_LUT_MIP_OFFSET 1.0
// Density blow wich we consider the density is zero (optimization reasons)
#define CLOUD_DENSITY_TRESHOLD 0.001f
// Number of steps before we start the large steps
#define EMPTY_STEPS_BEFORE_LARGE_STEPS 8
// Forward eccentricity
#define FORWARD_ECCENTRICITY 0.7
// Forward eccentricity
#define BACKWARD_ECCENTRICITY 0.7
// Distance until which the erosion texture i used
#define MIN_EROSION_DISTANCE 3000.0
#define MAX_EROSION_DISTANCE 300000.0
// Value that is used to normalize the noise textures
#define NOISE_TEXTURE_NORMALIZATION_FACTOR 100000.0f
// Maximal distance until which the "skybox"
#define MAX_SKYBOX_VOLUMETRIC_CLOUDS_DISTANCE 200000.0f
// Maximal size of a light step
#define LIGHT_STEP_MAXIMAL_SIZE 1000.0f
// Threshold at which the clouds are considered inexistant (Found experimentally)
#define TRANSMITTANCE_DISCARD_THRESHOLD 0.992

// HDRP generic includes
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Common.hlsl"
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Color.hlsl"
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/GeometricTools.hlsl"
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/EntityLighting.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/ShaderLibrary/ShaderVariables.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/Sky/PhysicallyBasedSky/ShaderVariablesPhysicallyBasedSky.cs.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/Sky/PhysicallyBasedSky/PhysicallyBasedSkyCommon.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/Lighting/VolumetricLighting/VolumetricCloudsDef.cs.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/RenderPipeline/Raytracing/Shaders/RaytracingSampling.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/Material/Builtin/BuiltinData.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/Lighting/ScreenSpaceLighting/BilateralUpsample.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/RenderPipeline/Raytracing/Shaders/RayTracingCommon.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/Lighting/AtmosphericScattering/AtmosphericScattering.hlsl"

// Input textures
TEXTURE2D_X(_HalfResDepthBuffer);
TEXTURE2D_X(_DepthTexture);
TEXTURE2D_X(_VolumetricCloudsSourceDepth);
TEXTURE2D_X(_MaxZMaskTexture);
Texture2D<float4> _CloudMapTexture;
Texture2D<float3> _CloudLutTexture;

// Noise textures for adding details
Texture3D<float> _Worley128RGBA;
Texture3D<float> _ErosionNoise;

// Texture that has just been traced
TEXTURE2D_X(_CloudsLightingTexture);
TEXTURE2D_X(_CloudsDepthTexture);

// History buffers
TEXTURE2D_X(_HistoryVolumetricClouds0Texture);
TEXTURE2D_X(_HistoryVolumetricClouds1Texture);

// Output texture
RW_TEXTURE2D_X(float, _DepthBufferRW);
RW_TEXTURE2D_X(float, _HalfResDepthBufferRW);
RW_TEXTURE2D_X(float4, _CloudsLightingTextureRW);
RW_TEXTURE2D_X(float, _CloudsDepthTextureRW);
RW_TEXTURE2D_X(float3, _CloudsAdditionalTextureRW);

#define REAL_TIME_VOLUMETRIC_CLOUDS
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/Lighting/VolumetricLighting/VolumetricCloudsUtilities.hlsl"

float3 GetCloudViewDirWS(float2 positionCS)
{
    float4 viewDirWS = mul(float4(positionCS.xy, 1.0f, 1.0f), _CloudsPixelCoordToViewDirWS);
    return -normalize(viewDirWS.xyz);
}

float ConvertObliqueDepthToNonOblique(int2 currentCoord, float obliqueDepth)
{
    // Compute the world position of the tapped pixel
    // Note: the view matrix here is not really used, but a valid matrix needs to be passed to this function.
    PositionInputs centralPosInput = GetPositionInput(currentCoord, _FinalScreenSize.zw, obliqueDepth, UNITY_MATRIX_I_VP, UNITY_MATRIX_V);

    // For some reason, with oblique matrices, when the point is on the background the reconstructed position ends up behind the camera and at the wrong position
    float3 rayDirection = normalize(-centralPosInput.positionWS);
    rayDirection = obliqueDepth == 0.0 ? -rayDirection : rayDirection;

    // Adjust the position
    centralPosInput.positionWS = obliqueDepth == 0.0 ? rayDirection * _ProjectionParams.z : centralPosInput.positionWS;

    // Re-do the projection, but this time without the oblique part and export it
    float4 hClip = mul(_CameraViewProjection_NO, float4(centralPosInput.positionWS, 1.0));

    return saturate(hClip.z / hClip.w);
}

[numthreads(8, 8, 1)]
void ConvertObliqueDepth(uint3 currentCoord : SV_DispatchThreadID, uint2 groupThreadId : SV_GroupThreadID, uint2 groupId : SV_GroupID)
{
    UNITY_XR_ASSIGN_VIEW_INDEX(currentCoord.z);

    // If this is bigger than the trace size, we are done
    if (any(currentCoord.xy >= uint2(_FinalScreenSize.xy)))
        return;

    // Combine it with the current shift to define which half res depth should be used
    _DepthBufferRW[COORD_TEXTURE2D_X(currentCoord.xy)] = ConvertObliqueDepthToNonOblique(currentCoord.xy, LOAD_TEXTURE2D_X(_DepthTexture, currentCoord.xy).x);
}

[numthreads(8, 8, 1)]
void DownscaleDepth(uint3 intermediateCoord : SV_DispatchThreadID, uint2 groupThreadId : SV_GroupThreadID, uint2 groupId : SV_GroupID)
{
    UNITY_XR_ASSIGN_VIEW_INDEX(intermediateCoord.z);

    // If this is bigger than the trace size, we are done
    if (any(intermediateCoord.xy >= uint2(_IntermediateScreenSize.xy)))
        return;

    // TODO USE LDS for this
    float depth0 = LOAD_TEXTURE2D_X(_DepthTexture, intermediateCoord.xy * 2.0).x;
    float depth1 = LOAD_TEXTURE2D_X(_DepthTexture, intermediateCoord.xy * 2.0 + int2(0, 1)).x;
    float depth2 = LOAD_TEXTURE2D_X(_DepthTexture, intermediateCoord.xy * 2.0 + int2(1, 1)).x;
    float depth3 = LOAD_TEXTURE2D_X(_DepthTexture, intermediateCoord.xy * 2.0 + int2(1, 0)).x;

    // Combine it with the current shift to define which half res depth should be used
    _HalfResDepthBufferRW[COORD_TEXTURE2D_X(intermediateCoord.xy)] = min(min(depth0, depth1), min(depth2, depth3));
}

// Structure that holds all the lighting data required to light the cloud particles
struct EnvironmentLighting
{
    // Light direction (point to sun)
    float3 sunDirection;
    // Light intensity/color of the sun, this already takes into account the atmospheric scattering
    float3 sunColor0;
    float3 sunColor1;
    // Ambient term from the ambient probe
    float3 ambientTermTop;
    float3 ambientTermBottom;
};

// Structure that holds all the data required for the cloud ray marching
struct CloudRay
{
    // Depth value of the pixel
    float depthValue;
    // Origin of the ray in world space
    float3 originWS;
    // Direction of the ray in world space
    float3 direction;
    // Maximal ray length before hitting the far plane or an occluder
    float maxRayLength;
    // Flag to track if we are inside the cloud layers
    float insideClouds;
    // Distance to earth center
    float toEarthCenter;
    // Integration Noise
    float integrationNoise;
    // Environement lighting
    EnvironmentLighting envLighting;
};

CloudRay BuildRay(uint2 intermediateCoord, float integrationNoise)
{
    CloudRay ray;
    ZERO_INITIALIZE(CloudRay, ray);

    // Keep track of the integration noise
    ray.integrationNoise = integrationNoise;

#ifdef LOCAL_VOLUMETRIC_CLOUDS
    // Grab the depth value of the pixel
    ray.depthValue = LOAD_TEXTURE2D_X(_VolumetricCloudsSourceDepth, intermediateCoord.xy).x;

    // Flag is this sky pixel occluded by an object?
    float isOccluded = ray.depthValue != UNITY_RAW_FAR_CLIP_VALUE ? 1.0 : 0.0;
#else
    ray.depthValue = UNITY_RAW_FAR_CLIP_VALUE;
    // Flag is this sky pixel occluded by an object?
    float isOccluded = 0.0;
#endif

    if (_RenderForSky)
    {
        // normalize to get the direction
        ray.direction = GetCloudViewDirWS(_LowResolutionEvaluation ? intermediateCoord * 2 : intermediateCoord);

        // Compute the max cloud ray length
        ray.maxRayLength = MAX_SKYBOX_VOLUMETRIC_CLOUDS_DISTANCE;
    }
    else
    {
        // Compute the world space position of the pixel (or at a virtual position is it the sky)
        float3 pos = ComputeWorldSpacePosition((intermediateCoord + 0.5) * _IntermediateScreenSize.zw, lerp(0.5, ray.depthValue, isOccluded), _IsPlanarReflection ? _CameraInverseViewProjection_NO : UNITY_MATRIX_I_VP);

        // normalize to get the direction
        ray.direction = normalize(pos);

        // Compute the max cloud ray length
        #ifdef LOCAL_VOLUMETRIC_CLOUDS
            ray.maxRayLength = lerp(_ProjectionParams.z, length(pos), isOccluded);
        #else
            ray.maxRayLength = MAX_SKYBOX_VOLUMETRIC_CLOUDS_DISTANCE;
        #endif
    }

    // Compute the position of the point from which the ray will start
#ifdef LOCAL_VOLUMETRIC_CLOUDS
    ray.originWS = _WorldSpaceCameraPos.xyz;
#else
    ray.originWS = float3(0, 0, 0);
#endif

    // Compute the distance to the center of the earth
    ray.toEarthCenter = length(ray.originWS + float3(0, _EarthRadius, 0));

    // Evaluate where the point is
    // -2.0 means under the surface of the earth
    // -1.0 means between the surface of the earth and the lower cloud bound
    // 0.0 means inside the cloud domain
    // 1.0 means above the cloud domain
    if (ray.toEarthCenter < _EarthRadius)
        ray.insideClouds = -2.0;
    else if (ray.toEarthCenter <= (_LowestCloudAltitude + _EarthRadius))
        ray.insideClouds = -1.0;
    else if (ray.toEarthCenter > (_HighestCloudAltitude + _EarthRadius))
        ray.insideClouds = 1.0f;
    else
        ray.insideClouds = 0.0;
    return ray;
}

bool PointInsideCloudVolume(float3 positionWS)
{
    float toEarthCenter2 = dot(positionWS, positionWS);
    return toEarthCenter2 < _CloudRangeSquared.y && toEarthCenter2 > _CloudRangeSquared.x;
}

bool GetCloudVolumeIntersection_Light(float3 originWS, float3 dir, out float totalDistance)
{
    // Given that this is a light ray, it will always start from inside the volume and is guaranteed to exit
    float2 intersection, intersectionEarth;
    RaySphereIntersection(originWS, dir, _HighestCloudAltitude + _EarthRadius, intersection);
    bool intersectEarth = RaySphereIntersection(originWS, dir, _EarthRadius);
    totalDistance = intersection.x;
    // If the ray intersects the earth, then the sun is occlued by the earth
    return !intersectEarth;
}

// Structure that describes the ray marching ranges that we should be iterating on
struct RayMarchRange
{
    // The start of the range
    float start;
    // The length of the range
    float distance;
};

bool GetCloudVolumeIntersection(float3 originWS, float3 dir, float insideClouds, float toEarthCenter, out RayMarchRange rayMarchRange)
#ifdef LOCAL_VOLUMETRIC_CLOUDS
{
    ZERO_INITIALIZE(RayMarchRange, rayMarchRange);

    // intersect with all three spheres
    float2 intersectionInter, intersectionOuter;
    int numInterInner = RaySphereIntersection(originWS, dir, _LowestCloudAltitude + _EarthRadius, intersectionInter);
    int numInterOuter = RaySphereIntersection(originWS, dir, _HighestCloudAltitude + _EarthRadius, intersectionOuter);
    bool intersectEarth = RaySphereIntersection(originWS, dir, insideClouds < -1.5 ? toEarthCenter : _EarthRadius);

    // Did we achieve any intersection ?
    bool intersect = numInterInner > 0 || numInterOuter > 0;

    // If we are inside the lower cloud bound
    if (insideClouds < -0.5)
    {
        // The ray starts at the first intersection with the lower bound and goes up to the first intersection with the outer bound
        rayMarchRange.start = intersectionInter.x;
        rayMarchRange.distance = intersectionOuter.x - intersectionInter.x;
    }
    else if (insideClouds == 0.0)
    {
        // If we are inside, the ray always starts at 0
        rayMarchRange.start = 0;

        // if we intersect the earth, this means the ray has only one range
        if (intersectEarth)
            rayMarchRange.distance = intersectionInter.x;
        // if we do not untersect the earth and the lower bound. This means the ray exits to outer space
        else if(numInterInner == 0)
            rayMarchRange.distance = intersectionOuter.x;
        // If we do not intersect the earth, but we do intersect the lower bound, we have two ranges.
        else
            rayMarchRange.distance = intersectionInter.x;
    }
    // We are in outer space
    else
    {
        // We always start from our intersection with the outer bound
        rayMarchRange.start = intersectionOuter.x;

        // If we intersect the earth, ony one range
        if(intersectEarth)
            rayMarchRange.distance = intersectionInter.x - intersectionOuter.x;
        else
        {
            // If we do not intersection the lower bound, the ray exits from the upper bound
            if(numInterInner == 0)
                rayMarchRange.distance = intersectionOuter.y - intersectionOuter.x;
            else
                rayMarchRange.distance = intersectionInter.x - intersectionOuter.x;
        }
    }
    // Mke sure we cannot go beyond what the number of samples
    rayMarchRange.distance = clamp(0, rayMarchRange.distance, _MaxRayMarchingDistance);

    // Return if we have an intersection
    return intersect;
}
#else
{
    ZERO_INITIALIZE(RayMarchRange, rayMarchRange);

    // intersect with all three spheres
    float2 intersectionInter, intersectionOuter;
    int numInterInner = RaySphereIntersection(originWS, dir, _LowestCloudAltitude + _EarthRadius, intersectionInter);
    int numInterOuter = RaySphereIntersection(originWS, dir, _HighestCloudAltitude + _EarthRadius, intersectionOuter);

    // The ray starts at the first intersection with the lower bound and goes up to the first intersection with the outer bound
    rayMarchRange.start = intersectionInter.x;
    rayMarchRange.distance = intersectionOuter.x - intersectionInter.x;

    // Return if we have an intersection
    return true;
}
#endif

// Structure that holds all the data used to define the cloud density of a point in space
struct CloudCoverageData
{
    // From a top down view, in what proportions this pixel has clouds
    float2 coverage;
    // From a top down view, in what proportions this pixel has clouds
    float rainClouds;
    // Value that allows us to request the cloudtype using the density
    float cloudType;
    // Maximal cloud height
    float maxCloudHeight;
};

float3 AnimateCloudMapPosition(float3 positionPS)
{
    return positionPS + float3(_WindVector.x, 0.0, _WindVector.y) * _LargeWindSpeed;
}

float3 AnimateBaseNoisePosition(float3 positionPS)
{
    // We reduce the top-view repetition of the pattern
    positionPS.y += (positionPS.x / 3.0f + positionPS.z / 7.0f);
    // We add the contribution of the wind displacements
    return positionPS + float3(_WindVector.x, 0.0, _WindVector.y) * _MediumWindSpeed + float3(0.0, _VerticalShapeWindDisplacement, 0.0);
}

float3 AnimateFineNoisePosition(float3 positionPS)
{
    return positionPS + float3(_WindVector.x, 0.0, _WindVector.y) * _SmallWindSpeed + float3(0.0, _VerticalErosionWindDisplacement, 0.0);
}

void GetCloudCoverageData(float3 positionPS, out CloudCoverageData data)
{
    // Convert the position into dome space and center the texture is centered above (0, 0, 0)
    float2 normalizedPosition = AnimateCloudMapPosition(positionPS).xz / _NormalizationFactor * _CloudMapTiling.xy + _CloudMapTiling.zw - 0.5;
    // Read the data from the texture
    float4 cloudMapData =  SAMPLE_TEXTURE2D_LOD(_CloudMapTexture, s_linear_repeat_sampler, float2(normalizedPosition), 0);
    data.coverage = float2(cloudMapData.x, cloudMapData.x * cloudMapData.x);
    data.rainClouds = cloudMapData.y;
    data.cloudType = cloudMapData.z;
    data.maxCloudHeight = cloudMapData.w;
}

float3 applyFastTonemapping(float3 input)
{
    if (_EnableFastToneMapping)
        return input*rcp(input + 1.0);
    else
        return input;
}

float3 unapplyFastTonemapping(float3 input)
{
    if (_EnableFastToneMapping)
        return input*rcp(1.0 - input);
    else
        return input;
}

void EvaluateSunColorAttenuation(float3 evaluationPointWS, float3 sunDirection, inout float3 sunColor)
{
#ifdef PHYSICALLY_BASED_SUN
    if(_PhysicallyBasedSun == 1)
    // TODO: move this into a shared function
    {
        float3 X = evaluationPointWS;
        float3 C = _PlanetCenterPosition.xyz;

        float r        = distance(X, C);
        float cosHoriz = ComputeCosineOfHorizonAngle(r);
        float cosTheta = dot(X - C, sunDirection) * rcp(r); // Normalize

        if (cosTheta >= cosHoriz) // Above horizon
        {
            float3 oDepth = ComputeAtmosphericOpticalDepth(r, cosTheta, true);
            // Cannot do this once for both the sky and the fog because the sky may be desaturated. :-(
            float3 transm  = TransmittanceFromOpticalDepth(oDepth);
            float3 opacity = 1 - transm;
            sunColor *= 1 - (Desaturate(opacity, _AlphaSaturation) * _AlphaMultiplier);
        }
        else
        {
            // return 0; // Kill the light. This generates a warning, so can't early out. :-(
           sunColor = 0;
        }
    }
#endif
}

EnvironmentLighting EvaluateEnvironmentLighting(CloudRay ray, float3 entryEvaluationPointWS, float3 exitEvaluationPointWS)
{
    // Sun parameters
    EnvironmentLighting environmentLight;
    environmentLight.sunDirection = _SunDirection.xyz;
    environmentLight.sunColor0 = _SunLightColor.xyz * GetCurrentExposureMultiplier();
    environmentLight.sunColor1 = environmentLight.sunColor0;
    environmentLight.ambientTermTop = _AmbientProbeTop.xyz * GetCurrentExposureMultiplier();
    environmentLight.ambientTermBottom = _AmbientProbeBottom.xyz * GetCurrentExposureMultiplier();

    // evaluate the attenuation at both points (entrance and exit of the cloud layer)
    EvaluateSunColorAttenuation(entryEvaluationPointWS, environmentLight.sunDirection, environmentLight.sunColor0);
    EvaluateSunColorAttenuation(exitEvaluationPointWS, environmentLight.sunDirection, environmentLight.sunColor1);
    return environmentLight;
}

struct CloudProperties
{
    // Normalized float that tells the "amount" of clouds that is at a given location
    float density;
    // Ambient occlusion for the ambient probe
    float ambientOcclusion;
    // Normalized value that tells us the height within the cloud volume (vertically)
    float height;
    // Transmittance of the cloud
    float sigmaT;
};

float EvaluateNormalizedCloudHeight(float3 positionPS)
{
    return (length(positionPS) - (_LowestCloudAltitude + _EarthRadius)) / ((_HighestCloudAltitude + _EarthRadius) - (_LowestCloudAltitude + _EarthRadius));
}

void EvaluateCloudProperties(float3 positionWS, float noiseMipOffset, float erosionMipOffset, bool cheapVersion, bool lightSampling, out CloudProperties properties)
{
    // Convert to planet space
    float3 positionPS = positionWS + float3(0, _EarthRadius, 0);

    // Initliaze all the values to 0 in case
    ZERO_INITIALIZE(CloudProperties, properties);

    // By default the ambient occlusion is 1.0
    properties.ambientOcclusion = 1.0;

    // If the next sampling point is not inside the coud volume the density
    if (!PointInsideCloudVolume(positionPS) || positionPS.y < 0.0f)
        return;

    // Compute the normalized position for the three channels
    float3 normalizedPos = positionPS / _NormalizationFactor;

    // Evaluate the normalized height of the position within the cloud volume
    properties.height = EvaluateNormalizedCloudHeight(positionPS);

    // Evaluate the generic sampling coordinates
    float3 baseNoiseSamplingCoordinates = float3(AnimateBaseNoisePosition(positionPS).xzy / NOISE_TEXTURE_NORMALIZATION_FACTOR) * _ShapeScale - float3(_ShapeNoiseOffset.x, _ShapeNoiseOffset.y, _VerticalShapeNoiseOffset);

    // Evaluate the coordinates at which the noise will be sampled and apply wind displacement
    baseNoiseSamplingCoordinates += properties.height * float3(_WindDirection.x, _WindDirection.y, 0.0f) * _AltitudeDistortion;

    // Read the low frequency Perlin-Worley and Worley noises
    float lowFrequencyNoise = SAMPLE_TEXTURE3D_LOD(_Worley128RGBA, s_trilinear_repeat_sampler, baseNoiseSamplingCoordinates.xyz, noiseMipOffset);

    // Initiliaze the erosion and shape factors (that will be overriden)
    float shapeFactor = lerp(0.1, 1.0, _ShapeFactor);
    float erosionFactor = _ErosionFactor;

    // Evaluate the cloud coverage data for this position
    CloudCoverageData cloudCoverageData;
    GetCloudCoverageData(positionPS, cloudCoverageData);

    // If this region of space has no cloud coverage, exit right away
    if (cloudCoverageData.coverage.x <= CLOUD_DENSITY_TRESHOLD || cloudCoverageData.maxCloudHeight < properties.height)
        return;

    // Read from the LUT
    float3 densityErosionAO = SAMPLE_TEXTURE2D_LOD(_CloudLutTexture, s_linear_clamp_sampler, float2(cloudCoverageData.cloudType, properties.height), CLOUD_LUT_MIP_OFFSET);

    // Adjust the shape and erosion factor based on the LUT and the coverage
    shapeFactor = shapeFactor * densityErosionAO.y;
    erosionFactor = erosionFactor * densityErosionAO.y;

    // Combine with the low frequency noise, we want less shaping for large clouds
    lowFrequencyNoise = lerp(1.0, lowFrequencyNoise, shapeFactor);
    float base_cloud = 1.0 - densityErosionAO.x * cloudCoverageData.coverage.x * (1.0 - shapeFactor);
    base_cloud = saturate(remap(lowFrequencyNoise, base_cloud, 1.0, 0.0, 1.0)) * cloudCoverageData.coverage.y;

    // Weight the ambient occlusion's contribution
    properties.ambientOcclusion = densityErosionAO.z;

    // Change the sigma based on the rain cloud data
    properties.sigmaT = lerp(0.04, 0.12, cloudCoverageData.rainClouds);

    // The ambient occlusion value that is baked is less relevant if there is shaping or erosion, small hack to compensate that
    float ambientOcclusionBlend = saturate(1.0 - max(erosionFactor, shapeFactor) * 0.5);
    properties.ambientOcclusion = lerp(1.0, properties.ambientOcclusion, ambientOcclusionBlend);

    // Apply the erosion for nifer details
    if (!cheapVersion)
    {
        float3 fineNoiseSamplingCoordinates = AnimateFineNoisePosition(positionPS) / NOISE_TEXTURE_NORMALIZATION_FACTOR * _ErosionScale;
        float highFrequencyNoise = 1.0 - SAMPLE_TEXTURE3D_LOD(_ErosionNoise, s_linear_repeat_sampler, fineNoiseSamplingCoordinates, CLOUD_DETAIL_MIP_OFFSET + erosionMipOffset).x;
        // Compute the weight of the low frequency noise
        highFrequencyNoise = lerp(0.0, highFrequencyNoise, erosionFactor * 0.75f * cloudCoverageData.coverage.x * _ErosionFactorCompensation);
        base_cloud = remap(base_cloud, highFrequencyNoise, 1.0, 0.0, 1.0);
        properties.ambientOcclusion = saturate(properties.ambientOcclusion - sqrt(highFrequencyNoise * _ErosionOcclusion));
    }

    // Given that we are not sampling the erosion texture, we compensate by substracting an erosion value
    if (lightSampling)
        base_cloud -= erosionFactor * 0.1;

    // Make sure we do not send any negative values
    base_cloud = max(0, base_cloud);

    // Attenuate everything by the density multiplier
    properties.density = base_cloud * _DensityMultiplier;
}

float3 EvaluateSunLuminance(float3 positionWS, float3 sunDirection, float3 sunColor, float density, float powderEffect, float phaseFunction[NUM_MULTI_SCATTERING_OCTAVES])
{
    // Compute the Ray to the limits of the cloud volume in the direction of the light
    float totalLightDistance = 0.0;
    float3 luminance = float3(0.0, 0.0, 0.0);

    // If we early out, this means we've hit the earth itself
    if (GetCloudVolumeIntersection_Light(positionWS, sunDirection, totalLightDistance))
    {
        // Because of the very limited numebr of light steps and the potential humongous distance to cover, we decide to potnetially cover less and make it more useful
        totalLightDistance = clamp(totalLightDistance, 0, _NumLightSteps * LIGHT_STEP_MAXIMAL_SIZE);

        // Apply a small bias to compensate for the imprecision in the ray-sphere intersection at world scale.
        totalLightDistance += 5.0f;

        // Initially the transmittance is one for all octaves
        float3 sunLightTransmittance[NUM_MULTI_SCATTERING_OCTAVES];
        int o;
        for (o = 0; o < NUM_MULTI_SCATTERING_OCTAVES; ++o)
            sunLightTransmittance[o] = 1.0;

        // Compute the size of the current step
        float stepSize = totalLightDistance / (float)_NumLightSteps;

        // Collect total density along light ray.
        float lastDist = 0;
        for (int j = 0; j < _NumLightSteps; j++)
        {
            // The samples are not linearly distributed along the point-light direction due to their low number. We sample they in a logarithmic way.
            float dist = stepSize * (0.25 + j);

            // Evaluate the current sample point
            float3 currentSamplePointWS = positionWS + sunDirection * dist;
            // Get the cloud properties at the sample point
            CloudProperties lightRayCloudProperties;
            EvaluateCloudProperties(currentSamplePointWS, 3.0f * j / _NumLightSteps, 0.0, true, true, lightRayCloudProperties);

            // Compute the extinction
            const float3 mediaExtinction = max(_ScatteringTint.xyz * lightRayCloudProperties.density * lightRayCloudProperties.sigmaT, float3(1e-6, 1e-6, 1e-6));

            // Update the transmittance for every octave
            for (o = 0; o < NUM_MULTI_SCATTERING_OCTAVES; ++o)
                sunLightTransmittance[o] *= exp(-stepSize * mediaExtinction * PositivePow(_MultiScattering, o));

            lastDist = dist;
        }

        // Compute the luminance for each octave
        for (o = 0; o < NUM_MULTI_SCATTERING_OCTAVES; ++o)
            luminance += sunLightTransmittance[o] * sunColor * powderEffect * phaseFunction[o] * PositivePow(_MultiScattering, o);
    }

    // return the combined luminance
    return luminance;
}

// Structure that holds the result of our volumetric ray
struct VolumetricRayResult
{
    float3 inScattering;
    float transmittance;
    float meanDistance;
    float finalStepCount;
    bool invalidRay;
};

void EvaluateCloud(CloudProperties cloudProperties, CloudRay cloudRay, float phaseFunction[NUM_MULTI_SCATTERING_OCTAVES],
                float3 currentPositionWS, float stepSize, float cosAngle, float relativeRayDistance,
                inout VolumetricRayResult volumetricRay)
{
    // Apply the extinction
    const float3 mediaExtinction = _ScatteringTint.xyz * cloudProperties.density * cloudProperties.sigmaT;
    const float currentStepExtinction = exp(-cloudProperties.density * cloudProperties.sigmaT * stepSize);

    // Compute the powder effect
    float powder_effect = PowderEffect(cloudProperties.density, cosAngle, _PowderEffectIntensity);

    // Evaluate the luminance at this sample
    const float3 luminance = (EvaluateSunLuminance(currentPositionWS, cloudRay.envLighting.sunDirection,
                                lerp(cloudRay.envLighting.sunColor0, cloudRay.envLighting.sunColor1, relativeRayDistance),
                                cloudProperties.density, powder_effect, phaseFunction)
                                + lerp(cloudRay.envLighting.ambientTermBottom, cloudRay.envLighting.ambientTermTop, cloudProperties.height)
                                * cloudProperties.ambientOcclusion) * mediaExtinction;

    // Improved analytical scattering
    const float3 integScatt = (luminance - luminance * currentStepExtinction) / mediaExtinction;
    volumetricRay.inScattering += integScatt * volumetricRay.transmittance;
    volumetricRay.transmittance *= currentStepExtinction;
}

float DensityFadeIn(float densityValue, float totalDistance)
{
    return lerp(0, densityValue, saturate((totalDistance - _FadeInStart) / (_FadeInStart + _FadeInDistance)));
}

VolumetricRayResult TraceVolumetricRay(CloudRay cloudRay)
{
    // Initiliaze the volumetric ray
    VolumetricRayResult volumetricRay;
    ZERO_INITIALIZE(VolumetricRayResult, volumetricRay);
    volumetricRay.inScattering = 0.0;
    volumetricRay.transmittance = 1.0;
    volumetricRay.meanDistance = _MaxCloudDistance;
    volumetricRay.finalStepCount = 0;
    volumetricRay.invalidRay = true;

    // Determine if ray intersects bounding volume, if the ray does not intersect the cloud volume AABB, skip right away
    RayMarchRange rayMarchRange;
    if (GetCloudVolumeIntersection(cloudRay.originWS, cloudRay.direction, cloudRay.insideClouds, cloudRay.toEarthCenter, rayMarchRange))
    {
        // Total distance that the ray must travel including empty spaces
        float totalDistance = rayMarchRange.distance;

        if (cloudRay.maxRayLength >= rayMarchRange.start)
        {
            volumetricRay.invalidRay = false;

            // Initialize the depth for accumulation
            volumetricRay.meanDistance = 0.0;

            // Clamp the travel distance to whatever is closer
            // - Sky Occluder
            // - Volume end
            // - Far plane
            totalDistance = min(totalDistance, cloudRay.maxRayLength - rayMarchRange.start);

            // Compute the environment lighting that is going to be used for the cloud evaluation
            cloudRay.envLighting = EvaluateEnvironmentLighting(cloudRay, cloudRay.originWS + rayMarchRange.start * cloudRay.direction, cloudRay.originWS + (rayMarchRange.start  + totalDistance) * cloudRay.direction);

            // Evaluate our integration step
            float stepS = totalDistance / (float)_NumPrimarySteps;

            // Evaluate cos of the theta angle between the view and light vectors
            float cosAngle = dot(cloudRay.direction, cloudRay.envLighting.sunDirection);

            // Evaluate the phase function for our ray direction
            float phaseFunction[NUM_MULTI_SCATTERING_OCTAVES];
            for (int o = 0; o < NUM_MULTI_SCATTERING_OCTAVES; ++o)
            {
                const float forwardP = HenyeyGreenstein(cosAngle, FORWARD_ECCENTRICITY * PositivePow(_MultiScattering, o));
                const float backwardsP = HenyeyGreenstein(cosAngle, -BACKWARD_ECCENTRICITY * PositivePow(_MultiScattering, o));
                phaseFunction[o] = backwardsP + forwardP;
            }

            // Initialize the cloud properties structure
            CloudProperties cloudProperties;
            ZERO_INITIALIZE(CloudProperties, cloudProperties);

            // Tracking the number of steps that have been made
            int currentIndex = 0;

            // Normalization value of the depth
            float meanDistanceDivider = 0.0f;

            // Current position for the evaluation
            float3 currentPositionWS = cloudRay.originWS + rayMarchRange.start * cloudRay.direction;

            // Current Distance that has been marched
            float currentDistance = 0;

            // Initialize the values for the optimized ray marching
            bool activeSampling = true;
            int sequentialEmptySamples = 0;

            // Do the ray march for every step that we can.
            while (currentIndex < _NumPrimarySteps && currentDistance < totalDistance)
            {
                // Should we be evaluating the clouds or just doing the large ray marching
                if (activeSampling)
                {
                    // Compute the mip offset for the erosion texture
                    float erosionMipOffset = lerp(0.0, 2.0, saturate((currentDistance - MIN_EROSION_DISTANCE) / (MAX_EROSION_DISTANCE - MIN_EROSION_DISTANCE)));

                    // If the density is null, we can skip as there will be no contribution
                    EvaluateCloudProperties(currentPositionWS, 0.0f, erosionMipOffset, false, false, cloudProperties);

                    // Apply the fade in function to the density
                    cloudProperties.density = DensityFadeIn(cloudProperties.density, rayMarchRange.start + currentDistance);

                    if (cloudProperties.density > CLOUD_DENSITY_TRESHOLD)
                    {
                        // Contribute to the average depth (must be done first in case we end up inside a cloud at the next step)
                        float transmitanceXdensity = volumetricRay.transmittance * cloudProperties.density;
                        volumetricRay.meanDistance += (rayMarchRange.start + currentDistance) * transmitanceXdensity;
                        meanDistanceDivider += transmitanceXdensity;

                        // Evaluate the cloud at the position
                        EvaluateCloud(cloudProperties, cloudRay, phaseFunction, currentPositionWS, stepS, cosAngle, currentDistance / totalDistance, volumetricRay);

                        // if most of the energy is absorbed, just leave.
                        if (volumetricRay.transmittance < 0.003)
                        {
                            volumetricRay.transmittance = 0.0;
                            break;
                        }

                        // Reset the empty sample counter
                        sequentialEmptySamples = 0;
                    }
                    else
                        sequentialEmptySamples++;

                    // If it has been more than EMPTY_STEPS_BEFORE_LARGE_STEPS, disable active sampling and start large steps
                    if (sequentialEmptySamples == EMPTY_STEPS_BEFORE_LARGE_STEPS)
                        activeSampling = false;

                    // Do the next step
                    float relativeStepSize = lerp(cloudRay.integrationNoise, 1.0, saturate(currentIndex));
                    currentPositionWS += cloudRay.direction * stepS * relativeStepSize;
                    currentDistance += stepS * relativeStepSize;
                }
                else
                {
                    // Sample the cheap version of the clouds
                    CloudProperties cloudProperties;
                    EvaluateCloudProperties(currentPositionWS, 1.0f, 0.0, true, false, cloudProperties);

                    // Apply the fade in function to the density
                    cloudProperties.density = DensityFadeIn(cloudProperties.density, rayMarchRange.start + currentDistance);

                    // If the density is lower than our tolerance,
                    if (cloudProperties.density < CLOUD_DENSITY_TRESHOLD)
                    {
                        currentPositionWS += cloudRay.direction * stepS * 2.0f;
                        currentDistance += stepS * 2.0f;
                    }
                    else
                    {
                        // Somewhere between this step and the previous clouds started
                        // We reset all the counters and enable active sampling
                        currentPositionWS -= cloudRay.direction * stepS;
                        currentDistance -= stepS;
                        activeSampling = true;
                        sequentialEmptySamples = 0;
                    }
                }

                currentIndex++;
            }

            // Compute the effective number of steps that have been marched
            volumetricRay.finalStepCount = (float)currentIndex / _NumPrimarySteps;

            // Normalized the depth we computed
            if (volumetricRay.meanDistance == 0.0)
                volumetricRay.invalidRay = true;
            else
                volumetricRay.meanDistance /= meanDistanceDivider;
        }
    }

    // return the final ray result
    return volumetricRay;
}

[numthreads(8, 8, 1)]
void RenderClouds(uint3 traceCoord : SV_DispatchThreadID, uint2 groupThreadId : SV_GroupThreadID, uint2 groupId : SV_GroupID)
{
    UNITY_XR_ASSIGN_VIEW_INDEX(traceCoord.z);

    // If this is bigger than the trace size, we are done
    if (any(traceCoord.xy >= uint2(_TraceScreenSize.xy)))
        return;

#if defined(DISTANT_VOLUMETRIC_CLOUDS)
    // Clear the cloud value
    _CloudsLightingTextureRW[COORD_TEXTURE2D_X(traceCoord.xy)] = float4(0.0, 0.0, 0.0, 1.0);

    // Grab the depth 2x2 region just to be safe
    float4 d = GATHER_RED_TEXTURE2D_X(_MaxZMaskTexture, s_point_clamp_sampler, traceCoord.xy / _TraceScreenSize.xy * _RTHandleScale.xy);
    // If there is any background pixel in the region we need to trace, otherwise we skip.
    if (all(d != 1e10f) && _ValidMaxZMask)
        return;
#endif

    // Depending on if we are in full res or not, use a different intermediate coord
    uint2 intermediateCoord = traceCoord.xy; // Full resolution case
    if (_LowResolutionEvaluation)
    {
        if (_EnableIntegration)
        {
            // Compute the half res coordinate that matches this thread (as we virtually do the computation in half res space)
            int checkerBoardIndex = ComputeCheckerBoardIndex(traceCoord.xy, _SubPixelIndex);
            intermediateCoord = traceCoord.xy * 2 + HalfResolutionIndexToOffset(checkerBoardIndex);
        }
        else
            intermediateCoord = traceCoord.xy * 2;
    }

    // Given that the rendering resolution is not guaranteed to be an even number, we need to clamp to the intermediate resolution in this case
    intermediateCoord = min(intermediateCoord, _IntermediateScreenSize.xy - 1);

    // Compute the offset that shall be used (if any)
    float offset = _EnableIntegration ? GetBNDSequenceSample(intermediateCoord, _AccumulationFrameIndex, 0) : 0.0;

    // Build the ray we will use of the ray marching.
    CloudRay ray = BuildRay(intermediateCoord, offset);

    // Evaluate the cloud transmittance
    VolumetricRayResult result = TraceVolumetricRay(ray);

    // Apply a fast tonemap
    result.inScattering = applyFastTonemapping(result.inScattering);

    // output the result
    _CloudsLightingTextureRW[COORD_TEXTURE2D_X(traceCoord.xy)] = float4(result.inScattering, result.transmittance);

    // Minimal distance to the clouds
    float minimalDistance = min(result.meanDistance, ray.maxRayLength);

    // If we are processing local clouds, we store the distance information as a depth, otherwise we just store the distance (for the fog).
#if defined(LOCAL_VOLUMETRIC_CLOUDS)
    // Compute the cloud depth
    float cloudMinDistance = clamp(minimalDistance, _ProjectionParams.y, _ProjectionParams.z);
    float cloudMinDepth = result.invalidRay ? ray.depthValue : ConvertCloudDepth(ray.direction * cloudMinDistance);
    _CloudsDepthTextureRW[COORD_TEXTURE2D_X(traceCoord.xy)] = cloudMinDepth;
#else
    // Output the cloud distance
    _CloudsDepthTextureRW[COORD_TEXTURE2D_X(traceCoord.xy)] = result.invalidRay ? ray.maxRayLength : max(minimalDistance, _ProjectionParams.y);
#endif
}

void FillCloudReprojectionLDS(uint groupIndex, uint2 groupOrigin)
{
    // Define which value we will be acessing with this worker thread
    int acessCoordX = groupIndex % 6;
    int acessCoordY = groupIndex / 6;

    // Everything we are accessing is in trace res (quarter rez).
    uint2 traceGroupOrigin = groupOrigin / 2;

    // The initial position of the access
    int2 originXY = traceGroupOrigin - int2(1, 1);

    // Compute the sample position
    int2 sampleCoord = int2(clamp(originXY.x + acessCoordX, 0, _TraceScreenSize.x - 1), clamp(originXY.y + acessCoordY, 0, _TraceScreenSize.y - 1));

    // The representative coordinate to use depends if we are using the checkerboard integration pattern (or not)
    int checkerBoardIndex = ComputeCheckerBoardIndex(sampleCoord, _SubPixelIndex);
    int2 representativeCoord = sampleCoord * 2 + (_EnableIntegration ? (int2)HalfResolutionIndexToOffset(checkerBoardIndex) : int2(0, 0));

    // Read the sample values
    float sampleDP = LOAD_TEXTURE2D_X(_HalfResDepthBuffer, representativeCoord).x;
    float4 sampleVal = LOAD_TEXTURE2D_X(_CloudsLightingTexture, sampleCoord);
    float sampleDC = LOAD_TEXTURE2D_X(_CloudsDepthTexture, sampleCoord).x;

    // Store into the LDS
    gs_cacheR[groupIndex] = sampleVal.r;
    gs_cacheG[groupIndex] = sampleVal.g;
    gs_cacheB[groupIndex] = sampleVal.b;
    gs_cacheA[groupIndex] = sampleVal.a;
    gs_cacheDP[groupIndex] = sampleDP;
    gs_cacheDC[groupIndex] = sampleDC;
}

float4 ClipCloudsToRegion(float4 history, float4 minimum, float4 maximum, inout float validityFactor)
{
    // The transmittance is overriden using a clamp
    float clampedTransmittance = clamp(history.w, minimum.w, maximum.w);

    // The lighting is overriden using a clip
    float3 center  = 0.5 * (maximum.xyz + minimum.xyz);
    float3 extents = 0.5 * (maximum.xyz - minimum.xyz);

    // This is actually `distance`, however the keyword is reserved
    float3 offset = history.xyz - center;
    float3 v_unit = offset.xyz / extents.xyz;
    float3 absUnit = abs(v_unit);
    float maxUnit = Max3(absUnit.x, absUnit.y, absUnit.z);

    // We make the history less valid if we had to clip it
    validityFactor *= maxUnit > 1.0 ? 0.5 : 1.0;

    if (maxUnit > 1.0)
        return float4(center + (offset / maxUnit), clampedTransmittance);
    else
        return float4(history.xyz, clampedTransmittance);
}

[numthreads(8, 8, 1)]
void REPROJECT_CLOUDS(uint3 dispatchThreadId : SV_DispatchThreadID,
                    int groupIndex : SV_GroupIndex,
                    uint2 groupThreadId : SV_GroupThreadID,
                    uint2 groupId : SV_GroupID)
{
    UNITY_XR_ASSIGN_VIEW_INDEX(dispatchThreadId.z);

    // Compute the set of coordinates we need
    uint2 intermediateCoord = dispatchThreadId.xy;
    uint2 fullResCoord = intermediateCoord * 2;
    uint2 traceCoord = intermediateCoord / 2;

#ifndef WITHOUT_LDS
    // Only 36 workers of the 64 do the pre-fetching
    if (groupIndex < 36)
    {
        // Load 1 value per thread
        FillCloudReprojectionLDS(groupIndex, groupId * 8);
    }
    // Make sure all values are loaded in LDS by now.
    GroupMemoryBarrierWithGroupSync();
#endif

#ifdef WITHOUT_LDS
    // Average the depth of the cloud
    float currentCloudDepth = LOAD_TEXTURE2D_X(_CloudsDepthTexture, traceCoord).x;
#else
    // Average the depth of the cloud
    float currentCloudDepth = GetCloudDepth_LDS(groupThreadId, int2(0, 0));
#endif

    // Compute the motionVector of the clouds
#ifdef LOCAL_VOLUMETRIC_CLOUDS
    float2 motionVector = EvaluateCloudMotionVectors(fullResCoord, currentCloudDepth, 1.0);
#else
    // If we are processing clouds as distant, we have no choice but to consider them very far.
    float2 motionVector = EvaluateCloudMotionVectors(fullResCoord, UNITY_RAW_FAR_CLIP_VALUE, 0.0);
#endif

    // Compute the history pixel coordinate to tap from
    float2 historyCoord = (intermediateCoord.xy + 0.5) - motionVector * _IntermediateScreenSize.xy;
    float2 clampedHistoryUV = clamp(historyCoord, 0.0, _IntermediateScreenSize.xy - 0.5f) / _IntermediateScreenSize.xy;

    // Read the volumetric cloud value from the previous frame
    float2 ratioScale = _HistoryViewportSize / _HistoryBufferSize;
    float2 historySampleCoords = clampedHistoryUV * ratioScale;

    // Grab the history values
    float4 previousResult = SAMPLE_TEXTURE2D_X_LOD(_HistoryVolumetricClouds0Texture, s_linear_clamp_sampler, historySampleCoords, 0);
    float3 previousResult1 = SAMPLE_TEXTURE2D_X_LOD(_HistoryVolumetricClouds1Texture, s_linear_clamp_sampler, historySampleCoords, 0).xyz;

    // Inverse the exposure of the previous frame and apply the current one (need to be done in linear space)
    previousResult.xyz = unapplyFastTonemapping(previousResult.xyz);
    previousResult.xyz *= GetInversePreviousExposureMultiplier() * GetCurrentExposureMultiplier();
    previousResult.xyz = applyFastTonemapping(previousResult.xyz);

    // Unpack the second buffer
    float previousSampleCount = previousResult1.x;
    float previousDepth = previousResult1.y;
    float previousCloudDepth = previousResult1.z;

    // This tracks if the history is considered valid
    bool validHistory = previousSampleCount >= 0.5f;

    // The history is invalid if we are requesting a value outside the frame
    if(historyCoord.x < 0.0 || historyCoord.x >= _IntermediateScreenSize.x || historyCoord.y < 0.0 || historyCoord.y >= _IntermediateScreenSize.y)
        validHistory = false;

    // Read the resolution of the current pixel
    float currentDepth = LOAD_TEXTURE2D_X(_HalfResDepthBuffer, intermediateCoord).x;

    // Compare the depth of the current pixel to the one of its history, if they are too different, we cannot consider this history valid
    float linearPrevDepth = Linear01Depth(previousDepth, _ZBufferParams);
    float linearCurrentDepth = Linear01Depth(currentDepth, _ZBufferParams);

    // We only need to check if the pixel depth coherence if the clouds can be behind and in front of the pixel
    if (abs(linearPrevDepth - linearCurrentDepth) > linearCurrentDepth * 0.2)
        validHistory = false;

    float validityFactor = 1.0;
#ifdef WITH_REJECTION
    // We need to validate that within the 3x3 trace region, at least one of the pixels is not a background pixel (incluing the clouds)
    float4 lightingMin = float4(FLT_MAX, FLT_MAX, FLT_MAX, 1.0);
    float4 lightingMax = float4(0, 0, 0, 0.0);
    for (int y = -1; y <= 1; ++y)
    {
        for (int x = -1; x <= 1; ++x)
        {
            #ifdef WITHOUT_LDS
            float4 cloudLigting = LOAD_TEXTURE2D_X(_CloudsLightingTexture, traceCoord + int2(x, y));
            #else
            float4 cloudLigting = GetCloudLighting_LDS(groupThreadId, int2(x, y));
            #endif
            lightingMin = min(lightingMin, cloudLigting);
            lightingMax = max(lightingMax, cloudLigting);
        }
    }

    if (currentDepth == UNITY_RAW_FAR_CLIP_VALUE)
        previousResult = ClipCloudsToRegion(previousResult, lightingMin, lightingMax, validityFactor);
#endif

    // Compute the local index that tells us the index of this pixel, the strategy for reprojection is a bit different in both cases
    int localIndex = (intermediateCoord.x & 1) + (intermediateCoord.y & 1) * 2;
    int currentIndex = ComputeCheckerBoardIndex(intermediateCoord / 2, _SubPixelIndex);
    if (localIndex == currentIndex)
    {
        // We need to validate that within the 3x3 trace region, at least one of the pixels is not a background pixel (incluing the clouds)
        float cloudNeighborhood = 0.0f;
        for (int y = -1; y <= 1; ++y)
        {
            for (int x = -1; x <= 1; ++x)
            {
                #ifdef WITHOUT_LDS
                if (LOAD_TEXTURE2D_X(_CloudsDepthTexture, traceCoord + int2(x, y)).x != 0.0f)
                    cloudNeighborhood += 1.0f;
                #else
                if (GetCloudDepth_LDS(groupThreadId, int2(x, y)) != 0.0f)
                    cloudNeighborhood += 1.0f;
                #endif
            }
        }

        // If the target coordinate is out of the screen, we cannot use the history
        float accumulationFactor = 0.0;
        float sampleCount = 1.0;
        if (validHistory && cloudNeighborhood != 0.0f)
        {
            // Define our accumation value
            accumulationFactor = previousSampleCount >= 16.0 ? 0.94117647058 : (previousSampleCount / (previousSampleCount + 1.0));
            accumulationFactor *= _TemporalAccumulationFactor * validityFactor;
            sampleCount = min(previousSampleCount + 1.0, 16.0);
        }

        // Accumulate the result with the previous frame
        #ifdef WITHOUT_LDS
        previousResult = accumulationFactor * previousResult + (1.0 - accumulationFactor) * LOAD_TEXTURE2D_X(_CloudsLightingTexture, traceCoord);
        #else
        previousResult = accumulationFactor * previousResult + (1.0 - accumulationFactor) * GetCloudLighting_LDS(groupThreadId, int2(0, 0));
        #endif
        previousSampleCount = sampleCount;
        previousDepth = currentDepth;
        previousCloudDepth = currentCloudDepth;
    }
    else
    {
        // Reduce the history validity a bit
        previousSampleCount *= _TemporalAccumulationFactor * validityFactor;

        // If the target coordinate is out of the screen or the depth that was used to generate it
        // is too different from the one of the current pixel, we cannot use the history
        if (!validHistory)
        {
            // Structure that will hold everything
            NeighborhoodUpsampleData3x3 upsampleData;
            #ifdef WITHOUT_LDS
            FillCloudReprojectionNeighborhoodData_NOLDS(traceCoord, localIndex, upsampleData);
            #else
            FillCloudReprojectionNeighborhoodData(groupThreadId, localIndex, upsampleData);
            #endif
            // Make sure that at least one of the pixels in the neighborhood can be used
            float rejectNeighborhood = 0.0f;
            int closestNeighbor = 4;
            OverrideMaskValues(currentDepth, upsampleData, rejectNeighborhood, closestNeighbor);

            // 1.0  if we were able to produce a value 0.0 if we failed to
            previousSampleCount = 1.0f - rejectNeighborhood;

            if (rejectNeighborhood == 1.0f)
            {
                // We don't have any valid history and there is no neighbor that is usable
                previousResult = 0.0f;
                previousSampleCount = 0.0f;
            }
            else
            {
                // We don't have any history for this pixel, but there is at least one neighbor that can be used in the current frame tracing
                previousSampleCount = 1.0f;
                previousResult = BilUpColor3x3(currentDepth, upsampleData);
            }
            #ifdef WITHOUT_LDS
            previousCloudDepth = LOAD_TEXTURE2D_X(_CloudsDepthTexture, traceCoord + IndexToLocalOffsetCoords[closestNeighbor]).x;
            #else
            previousCloudDepth = GetCloudDepth_LDS(groupThreadId, IndexToLocalOffsetCoords[closestNeighbor]);
            #endif
        }
        previousDepth = currentDepth;
    }

    // Make sure this doesn't go outside of the [0, 1] interval
    previousResult.w = saturate(previousResult.w);

    // Accumulate the result with the previous frame
    _CloudsLightingTextureRW[COORD_TEXTURE2D_X(intermediateCoord)] = previousResult;
    _CloudsAdditionalTextureRW[COORD_TEXTURE2D_X(intermediateCoord)] = float3(previousSampleCount, previousDepth, previousCloudDepth);
}

[numthreads(8, 8, 1)]
void PreUpscaleClouds(uint3 dispatchThreadId : SV_DispatchThreadID,
                    int groupIndex : SV_GroupIndex,
                    uint2 groupThreadId : SV_GroupThreadID,
                    uint2 groupId : SV_GroupID)
{
    UNITY_XR_ASSIGN_VIEW_INDEX(dispatchThreadId.z);

    // Compute the set of coordinates we need
    uint2 intermediateCoord = dispatchThreadId.xy;
    uint2 traceCoord = intermediateCoord / 2;

#ifndef WITHOUT_LDS
    // Only 36 workers of the 64 do the pre-fetching
    if (groupIndex < 36)
    {
        // Load 1 value per thread
        FillCloudReprojectionLDS(groupIndex, groupId * 8);
    }
    // Make sure all values are loaded in LDS by now.
    GroupMemoryBarrierWithGroupSync();
#endif

#ifdef WITHOUT_LDS
    // Average the depth of the cloud
    float currentCloudDepth = LOAD_TEXTURE2D_X(_CloudsDepthTexture, traceCoord).x;
#else
    // Average the depth of the cloud
    float currentCloudDepth = GetCloudDepth_LDS(groupThreadId, int2(0, 0));
#endif

    float cloudCloudDepth = 0;
    float currentDepth = LOAD_TEXTURE2D_X(_HalfResDepthBuffer, intermediateCoord).x;
    float4 cloudLighting = 0;

    // Compute the local index that tells us the index of this pixel, the strategy for reprojection is a bit different in both cases
    int localIndex = (intermediateCoord.x & 1) + (intermediateCoord.y & 1) * 2;
    int currentIndex = _EnableIntegration ? ComputeCheckerBoardIndex(intermediateCoord / 2, _SubPixelIndex) : 0;
    if (localIndex == currentIndex)
    {
        // Accumulate the result with the previous frame
        #ifdef WITHOUT_LDS
        cloudLighting = LOAD_TEXTURE2D_X(_CloudsLightingTexture, traceCoord);
        #else
        cloudLighting = GetCloudLighting_LDS(groupThreadId, int2(0, 0));
        #endif
        cloudCloudDepth = currentCloudDepth;
    }
    else
    {
        // Structure that will hold everything
        NeighborhoodUpsampleData3x3 upsampleData;
        #ifdef WITHOUT_LDS
        FillCloudReprojectionNeighborhoodData_NOLDS(traceCoord, localIndex, upsampleData);
        #else
        FillCloudReprojectionNeighborhoodData(groupThreadId, localIndex, upsampleData);
        #endif
        // Make sure that at least one of the pixels in the neighborhood can be used
        float rejectNeighborhood = 0.0f;
        int closestNeighbor = 4;
        OverrideMaskValues(currentDepth, upsampleData, rejectNeighborhood, closestNeighbor);

        // 1.0  if we were able to produce a value 0.0 if we failed to
        if (rejectNeighborhood == 1.0f)
        {
            // We don't have any valid history and there is no neighbor that is usable
            cloudLighting = 0.0f;
        }
        else
        {
            // We don't have any history for this pixel, but there is at least one neighbor that can be used in the current frame tracing
            cloudLighting = BilUpColor3x3(currentDepth, upsampleData);
        }
        #ifdef WITHOUT_LDS
        cloudCloudDepth = LOAD_TEXTURE2D_X(_CloudsDepthTexture, traceCoord + IndexToLocalOffsetCoords[closestNeighbor]).x;
        #else
        cloudCloudDepth = GetCloudDepth_LDS(groupThreadId, IndexToLocalOffsetCoords[closestNeighbor]);
        #endif
    }

    // Make sure this doesn't go outside of the [0, 1] interval
    cloudLighting.w = saturate(cloudLighting.w);

    // Accumulate the result with the previous frame
    _CloudsLightingTextureRW[COORD_TEXTURE2D_X(intermediateCoord)] = cloudLighting;
    _CloudsAdditionalTextureRW[COORD_TEXTURE2D_X(intermediateCoord)] = float3(1, currentDepth, cloudCloudDepth);
}

[numthreads(8, 8, 1)]
void PreUpscaleCloudsSky(uint3 dispatchThreadId : SV_DispatchThreadID,
                    int groupIndex : SV_GroupIndex,
                    uint2 groupThreadId : SV_GroupThreadID,
                    uint2 groupId : SV_GroupID)
{
    UNITY_XR_ASSIGN_VIEW_INDEX(dispatchThreadId.z);

    // Compute the set of coordinates we need
    uint2 intermediateCoord = dispatchThreadId.xy;
    uint2 traceCoord = intermediateCoord / 2;

#ifndef WITHOUT_LDS
    // Only 36 workers of the 64 do the pre-fetching
    if (groupIndex < 36)
    {
        // Load 1 value per thread
        FillCloudReprojectionLDS(groupIndex, groupId * 8);
    }
    // Make sure all values are loaded in LDS by now.
    GroupMemoryBarrierWithGroupSync();
#endif

    // If out of bounds, leave right away
    if (any(intermediateCoord.xy >= uint2(_IntermediateScreenSize.xy)))
        return;

    // Grab the cloud data
#ifdef WITHOUT_LDS
    float4 cloudLighting = LOAD_TEXTURE2D_X(_CloudsLightingTexture, traceCoord);
#else
    float4 cloudLighting = GetCloudLighting_LDS(groupThreadId, int2(0, 0));
#endif

    // Accumulate the result with the previous frame
    _CloudsLightingTextureRW[COORD_TEXTURE2D_X(intermediateCoord)] = cloudLighting;
}

// Constant buffer where all variables should land
CBUFFER_START(VolumetricCloudsUpscaleConstantBuffer)
    float2 _UpperScreenSize;
CBUFFER_END

// Half resolution volumetric cloud texture
TEXTURE2D_X(_VolumetricCloudsTexture);
TEXTURE2D_X(_DepthStatusTexture);

// Input output camera color buffer
#ifndef CAN_RW_ON_COLOR_BUFFER
TEXTURE2D_X(_CameraColorTexture);
#endif
RW_TEXTURE2D_X(float4, _VolumetricCloudsUpscaleTextureRW);

void FillLDSUpscale(uint groupIndex, uint2 groupOrigin)
{
    // Define which value we will be acessing with this worker thread
    int acessCoordX = groupIndex % 6;
    int acessCoordY = groupIndex / 6;

    // Everything we are accessing is in intermediate res (half rez).
    uint2 traceGroupOrigin = groupOrigin / 2;

    // The initial position of the access
    int2 originXY = traceGroupOrigin - int2(1, 1);

    // Compute the sample position
    int2 sampleCoord = int2(clamp(originXY.x + acessCoordX, 0, _IntermediateScreenSize.x - 1), clamp(originXY.y + acessCoordY, 0, _IntermediateScreenSize.y - 1));

    // Read the sample value
    float4 sampleVal = LOAD_TEXTURE2D_X(_VolumetricCloudsTexture, sampleCoord);
    float3 depthStatusValue = LOAD_TEXTURE2D_X(_DepthStatusTexture, sampleCoord).xyz;

    // Store into the LDS
    gs_cacheR[groupIndex] = sampleVal.r;
    gs_cacheG[groupIndex] = sampleVal.g;
    gs_cacheB[groupIndex] = sampleVal.b;
    gs_cacheA[groupIndex] = sampleVal.a;
    gs_cacheDP[groupIndex] = depthStatusValue.y;
    gs_cachePS[groupIndex] = saturate(depthStatusValue.x);
    gs_cacheDC[groupIndex] = depthStatusValue.z;
}

[numthreads(8, 8, 1)]
void UPSAMPLE_KERNEL(uint3 finalCoord : SV_DispatchThreadID,
                            int groupIndex : SV_GroupIndex,
                            uint2 groupThreadId : SV_GroupThreadID,
                            uint2 groupId : SV_GroupID)
{
    UNITY_XR_ASSIGN_VIEW_INDEX(finalCoord.z);

    // Only 36 workers of the 64 do the pre-fetching
    if (groupIndex < 36)
    {
        // Load 1 value per thread
        FillLDSUpscale(groupIndex, groupId * 8);
    }

    // Make sure all values are loaded in LDS by now.
    GroupMemoryBarrierWithGroupSync();

    // If out of bounds, leave right away
    if (any(finalCoord.xy >= uint2(_FinalScreenSize.xy)))
        return;

    // Grab the depth value of the pixel
    float highDepth = LOAD_TEXTURE2D_X(_DepthTexture, finalCoord.xy).x;

    // Compute the index of the pixel in the 2x2 region (L->R, T->B)
    uint subRegionIndex = (finalCoord.x & 1) + (finalCoord.y & 1) * 2;

    // Structure that will hold everything
    NeighborhoodUpsampleData3x3 upsampleData;

    // Fill the sample data
    FillCloudUpscaleNeighborhoodData(groupThreadId.xy, subRegionIndex, upsampleData);

#ifdef LOCAL_VOLUMETRIC_CLOUDS
    // Flag that tells us which pixel holds valid information
    float rejectedNeighborhood = 0.0;
    int closestNeighbor = 4;
    OverrideMaskValues(highDepth, upsampleData, rejectedNeighborhood, closestNeighbor);

    // Do the bilateral upscale
    float4 currentClouds = BilUpColor3x3(highDepth, upsampleData);
    // Read the fallback value and use it if we defined that it was impossible for us to do something about it
    if (rejectedNeighborhood == 1.0f)
        currentClouds = float4(0.0, 0.0, 0.0, 1.0);
#else
    upsampleData.lowDepthA = UNITY_RAW_FAR_CLIP_VALUE;
    upsampleData.lowDepthB = UNITY_RAW_FAR_CLIP_VALUE;
    upsampleData.lowDepthC = UNITY_RAW_FAR_CLIP_VALUE;
    float4 currentClouds = highDepth == UNITY_RAW_FAR_CLIP_VALUE ? BilUpColor3x3(highDepth, upsampleData) : float4(0.0, 0.0, 0.0, 1.0);
#endif

    // De-tonemap the inscattering value
    currentClouds.xyz = unapplyFastTonemapping(currentClouds.xyz);
    currentClouds.w = saturate(currentClouds.w);

    // Due to numerical precision issues, upscaling a bunch of 1.0 can lead to a slightly lower number, this fixes it.
    currentClouds.w = currentClouds.w > TRANSMITTANCE_DISCARD_THRESHOLD ? 1.0 : currentClouds.w;

#ifdef LOCAL_VOLUMETRIC_CLOUDS
    float cloudDepth = GetCloudDepth_LDS(groupThreadId, IndexToLocalOffsetCoords[closestNeighbor]);
#else
    float cloudDepth = UNITY_RAW_FAR_CLIP_VALUE;
#endif

    // Compute the pos input of the cloud position
    PositionInputs cloudPosInput = GetPositionInput(finalCoord.xy, _FinalScreenSize.zw, cloudDepth, _IsPlanarReflection ? _CameraInverseViewProjection_NO : UNITY_MATRIX_I_VP, GetWorldToViewMatrix(), 0);

    // Compute the view direction
    float3 viewDir = -normalize(cloudPosInput.positionWS);

    // If the clouds are distant clouds, we need to adjust the position world space as the far plane is probably too close for the fog to be correct
#if defined(DISTANT_VOLUMETRIC_CLOUDS)
    float cloudDistance = GetCloudDepth_LDS(groupThreadId, 0);
    cloudPosInput.positionWS = -viewDir * cloudDistance;
#endif

#ifdef USE_INTERMEDIATE_BUFFER
    // Compute the fog attenuation of the clouds
    float3 fogColor;
    float3 fogOpacity;
    EvaluateAtmosphericScattering(cloudPosInput, viewDir, fogColor, fogOpacity);
    currentClouds.xyz = currentClouds.xyz * (1 - fogOpacity) + fogColor * (1.0 - (_CubicTransmittance ? currentClouds.a * currentClouds.a : currentClouds.a));

    // Store the upscaled result only, composite in later pass.
    _VolumetricCloudsUpscaleTextureRW[COORD_TEXTURE2D_X(finalCoord.xy)] = currentClouds;
#else
    // Read the color buffer
#ifdef CAN_RW_ON_COLOR_BUFFER
    float4 currentColor = _VolumetricCloudsUpscaleTextureRW[COORD_TEXTURE2D_X(finalCoord.xy)];
#else
    float4 currentColor = _CameraColorTexture[COORD_TEXTURE2D_X(finalCoord.xy)];
#endif

    // Estimate the transmittance that shall be used
    float finalTransmittance = EvaluateFinalTransmittance(currentColor.rgb, currentClouds.w);

    // Compute the fog attenuation of the clouds
    float3 fogColor;
    float3 fogOpacity;
    EvaluateAtmosphericScattering(cloudPosInput, viewDir, fogColor, fogOpacity);
    currentClouds.xyz = currentClouds.xyz * (1 - fogOpacity) + fogColor * (1.0 - finalTransmittance);

    // Apply the transmittance
    _VolumetricCloudsUpscaleTextureRW[COORD_TEXTURE2D_X(finalCoord.xy)] = float4(currentColor.xyz * finalTransmittance + currentClouds.xyz, currentColor.a);
#endif
}

[numthreads(8, 8, 1)]
void UPSAMPLE_KERNEL_SKY(uint3 finalCoord : SV_DispatchThreadID,
                            int groupIndex : SV_GroupIndex,
                            uint2 groupThreadId : SV_GroupThreadID,
                            uint2 groupId : SV_GroupID)
{
    UNITY_XR_ASSIGN_VIEW_INDEX(finalCoord.z);

    // Only 36 workers of the 64 do the pre-fetching
    if (groupIndex < 36)
    {
        // Load 1 value per thread
        FillLDSUpscale(groupIndex, groupId * 8);
    }

    // Make sure all values are loaded in LDS by now.
    GroupMemoryBarrierWithGroupSync();

    // If out of bounds, leave right away
    if (any(finalCoord.xy >= uint2(_FinalScreenSize.xy)))
        return;

    float4 currentClouds = GetCloudLighting_LDS(groupThreadId, int2(0, 0));

    // De-tonemap the inscattering value
    currentClouds.xyz = unapplyFastTonemapping(currentClouds.xyz);
    currentClouds.w = saturate(currentClouds.w);

    // Due to numerical precision issues, upscaling a bunch of 1.0 can lead to a slightly lower number, this fixes it.
    currentClouds.w = currentClouds.w > TRANSMITTANCE_DISCARD_THRESHOLD ? 1.0 : currentClouds.w;

    // Store the upscaled result only, composite in later pass.
    _VolumetricCloudsUpscaleTextureRW[COORD_TEXTURE2D_X(finalCoord.xy)] = currentClouds;
}

[numthreads(8, 8, 1)]
void COMBINE_KERNEL(uint3 finalCoord : SV_DispatchThreadID,
                            int groupIndex : SV_GroupIndex,
                            uint2 groupThreadId : SV_GroupThreadID,
                            uint2 groupId : SV_GroupID)
{
    UNITY_XR_ASSIGN_VIEW_INDEX(finalCoord.z);

    // If out of bounds, leave right away
    if (any(finalCoord.xy >= uint2(_FinalScreenSize.xy)))
        return;

    // Grab the depth value of the pixel
    float highDepth = LOAD_TEXTURE2D_X(_DepthTexture, finalCoord.xy).x;
    float4 sampleVal = LOAD_TEXTURE2D_X(_VolumetricCloudsTexture, finalCoord.xy);

#ifdef LOCAL_VOLUMETRIC_CLOUDS
    // Do the bilateral upscale
    float4 currentClouds = sampleVal;
#else
    float4 currentClouds = highDepth == UNITY_RAW_FAR_CLIP_VALUE ? sampleVal : float4(0.0, 0.0, 0.0, 1.0);
#endif

    // De-tonemap the inscattering value
    currentClouds.xyz = unapplyFastTonemapping(currentClouds.xyz);
    currentClouds.w = saturate(currentClouds.w);

    // Due to numerical precision issues, upscaling a bunch of 1.0 can lead to a slightly lower number, this fixes it.
    currentClouds.w = currentClouds.w > TRANSMITTANCE_DISCARD_THRESHOLD ? 1.0 : currentClouds.w;

#ifdef LOCAL_VOLUMETRIC_CLOUDS
    float cloudsDepth = LOAD_TEXTURE2D_X(_DepthStatusTexture, finalCoord.xy).z;
#else
    float cloudsDepth = UNITY_RAW_FAR_CLIP_VALUE;
#endif

    // Compute the pos input of the cloud position
    PositionInputs cloudPosInput = GetPositionInput(finalCoord.xy, _FinalScreenSize.zw, cloudsDepth, UNITY_MATRIX_I_VP, GetWorldToViewMatrix(), 0);

    // Compute the view direction
    float3 viewDir = -normalize(cloudPosInput.positionWS);

    // If the clouds are distant clouds, we need to adjust the position world space as the far plane is probably too close for the fog to be correct
#if defined(DISTANT_VOLUMETRIC_CLOUDS)
    float cloudDistance = GetCloudDepth_LDS(groupThreadId, 0);
    cloudPosInput.positionWS = -viewDir * LOAD_TEXTURE2D_X(_DepthStatusTexture, finalCoord.xy).z;
#endif

    // Compute the fog attenuation of the clouds
    float3 fogColor;
    float3 fogOpacity;
    EvaluateAtmosphericScattering(cloudPosInput, viewDir, fogColor, fogOpacity);
    currentClouds.xyz = currentClouds.xyz * (1 - fogOpacity) + fogColor * (1.0 - currentClouds.a);

#ifdef USE_INTERMEDIATE_BUFFER
    // Store the upscaled result only, composite in later pass.
    _VolumetricCloudsUpscaleTextureRW[COORD_TEXTURE2D_X(finalCoord.xy)] = currentClouds;
#else
    // Read the color buffer
#ifdef CAN_RW_ON_COLOR_BUFFER
    float4 currentColor = _VolumetricCloudsUpscaleTextureRW[COORD_TEXTURE2D_X(finalCoord.xy)];
#else
    float4 currentColor = _CameraColorTexture[COORD_TEXTURE2D_X(finalCoord.xy)];
#endif
    // If this is a background pixel, we want the cloud value, otherwise we do not.
    _VolumetricCloudsUpscaleTextureRW[COORD_TEXTURE2D_X(finalCoord.xy)] = float4(currentColor.xyz * currentClouds.a + currentClouds.xyz, currentColor.a);
#endif
}

[numthreads(8, 8, 1)]
void COMBINE_KERNEL_SKY(uint3 finalCoord : SV_DispatchThreadID)
{
    UNITY_XR_ASSIGN_VIEW_INDEX(finalCoord.z);

    // If out of bounds, leave right away
    if (any(finalCoord.xy >= uint2(_FinalScreenSize.xy)))
        return;

    // Grab the depth value of the pixel
    float4 currentClouds = LOAD_TEXTURE2D_X(_VolumetricCloudsTexture, finalCoord.xy);

    // De-tonemap the inscattering value
    currentClouds.xyz = unapplyFastTonemapping(currentClouds.xyz);
    currentClouds.w = saturate(currentClouds.w);

    // Due to numerical precision issues, upscaling a bunch of 1.0 can lead to a slightly lower number, this fixes it.
    currentClouds.w = currentClouds.w > TRANSMITTANCE_DISCARD_THRESHOLD ? 1.0 : currentClouds.w;

    // Store the upscaled result only, composite in later pass.
    _VolumetricCloudsUpscaleTextureRW[COORD_TEXTURE2D_X(finalCoord.xy)] = currentClouds;
}

RW_TEXTURE2D(float3, _VolumetricCloudsShadowRW);

[numthreads(8, 8, 1)]
void ComputeVolumetricCloudsShadow(uint3 currentCoords : SV_DispatchThreadID, uint2 groupThreadId : SV_GroupThreadID, uint2 groupId : SV_GroupID)
{
    UNITY_XR_ASSIGN_VIEW_INDEX(currentCoords.z);

    if (currentCoords.x == 0 || currentCoords.y == 0 || ((int)currentCoords.x) == (_ShadowCookieResolution - 1) || ((int)currentCoords.y) == (_ShadowCookieResolution - 1))
    {
        _VolumetricCloudsShadowRW[currentCoords.xy] = _ShadowFallbackValue;
        return;
    }

    // First we compute the location of the shadow plane in the planet coordinate system
    float3 shadowPlaneOrigin = _SunDirection.xyz * (_HighestCloudAltitude + _EarthRadius);
    float3 shadowPlaneNormal = -_SunDirection.xyz;

    // Here the plane is guaranteed to intersect, we don't need to test the result
    float t;
    IntersectPlane(0, _SunDirection.xyz, shadowPlaneOrigin, shadowPlaneNormal, t);

    // Compute the position of the shadow plane
#ifdef LOCAL_VOLUMETRIC_CLOUDS
    float3 shadowCookieCenterWS = float3(_WorldSpaceShadowCenter.x, _ShadowPlaneOffset, _WorldSpaceShadowCenter.z) + t * _SunDirection.xyz;
#else
    float3 shadowCookieCenterWS = t * _SunDirection.xyz;
#endif

    // Compute the normalized coordinate on the shadow plane
    float2 normalizedCoord = (currentCoords.xy - _ShadowCookieResolution * 0.5f) / (_ShadowCookieResolution * 0.5f);

    // Compute the origin of the ray properties  in the planet space
    float3 rayOriginWS = (normalizedCoord.x * _SunRight.xyz * _ShadowRegionSize.x + normalizedCoord.y * _SunUp.xyz * _ShadowRegionSize.y) + shadowCookieCenterWS;
    float3 rayDirection = -_SunDirection.xyz;

    // Compute the attenuation
    float transmittance = 1.0f;

    // Intersect the outer sphere
    float2 intersectionO, intersectionI;
    int numIntersectionO = RaySphereIntersection(rayOriginWS, rayDirection, _HighestCloudAltitude + _EarthRadius, intersectionO);
    int numIntersectionI = RaySphereIntersection(rayOriginWS, rayDirection, _LowestCloudAltitude + _EarthRadius, intersectionI);
    if (numIntersectionO != 0 && numIntersectionI != 0)
    {
        // Compute the integration range
        float startDistance = intersectionO.x;
        float totalDistance = intersectionI.x - intersectionO.x;

        float stepSize = totalDistance / 16;

        for (int i = 0; i < 16; ++i)
        {
            // Compute the sphere intersection position
            float3 positionWS = rayOriginWS + rayDirection * (intersectionO.x + stepSize * i);

            // Get the coverage at intersection point
            CloudCoverageData cloudCoverageData;
            GetCloudCoverageData(positionWS, cloudCoverageData);

            // Compute the cloud density
            CloudProperties cloudProperties;
            EvaluateCloudProperties(positionWS, 0.0, 0.0, true, true, cloudProperties);

            // Apply the camera fade it to match the clouds perceived by the camera
            cloudProperties.density = DensityFadeIn(cloudProperties.density, length(positionWS - _WorldSpaceShadowCenter.xyz));

            if (cloudProperties.density > CLOUD_DENSITY_TRESHOLD)
            {
                // Apply the extinction
                const float3 currentStepExtinction = exp(-_ScatteringTint.xyz * cloudProperties.density * cloudProperties.sigmaT * stepSize);
                transmittance *= Luminance(currentStepExtinction);
            }
        }
    }

    _VolumetricCloudsShadowRW[currentCoords.xy] = lerp(1.0 - _ShadowIntensity, 1.0, transmittance);
}

// LDS used to pre-fetch the neighborhood data a 8x8 region with a one pixel border (10x10)
groupshared uint gs_cacheShadow[100];

TEXTURE2D(_VolumetricCloudsShadow);

void FillShadowLDSData(uint elementIndex, uint2 groupOrigin)
{
    // Define which value we will be acessing with this worker thread
    int acessCoordX = elementIndex % 10;
    int acessCoordY = elementIndex / 10;

    // The initial position of the access
    int2 originXY = (int2)groupOrigin - int2(1, 1) + int2(acessCoordX, acessCoordY);

    // Compute the sample position
    int2 tapCoord = int2(clamp(originXY.x, 0, _ShadowCookieResolution - 1), clamp(originXY.y, 0, _ShadowCookieResolution - 1));

    // Read the value from the texture
    float3 shadowValue = LOAD_TEXTURE2D(_VolumetricCloudsShadow, tapCoord.xy).xyz;

    // Pack it and store it into the LDS
    gs_cacheShadow[elementIndex] = PackToR11G11B10f(shadowValue);
}

uint ShadowOffsetToLDSAdress(uint2 groupThreadId, int2 offset)
{
    // Compute the tap coordinate in the 10x10 grid
    uint2 tapAddress = (uint2)((int2)(groupThreadId + 1) + offset);
    return clamp((uint)(tapAddress.x) % 10 + tapAddress.y * 10, 0, 99);
}

[numthreads(8, 8, 1)]
void FilterVolumetricCloudsShadow(uint3 currentCoords : SV_DispatchThreadID, int groupIndex : SV_GroupIndex, uint2 groupThreadId : SV_GroupThreadID, uint2 groupId : SV_GroupID)
{
    UNITY_XR_ASSIGN_VIEW_INDEX(currentCoords.z);

    // Fill the LDS with the shadow data
    if (groupIndex < 50)
    {
        FillShadowLDSData(groupIndex * 2, groupId * 8);
        FillShadowLDSData(groupIndex * 2 + 1, groupId * 8);
    }
    GroupMemoryBarrierWithGroupSync();

    // Grab the center pixel
    float3 centerShadow = UnpackFromR11G11B10f(gs_cacheShadow[ShadowOffsetToLDSAdress(groupThreadId, int2(0, 0))]);

    // Average the 3x3 rgion
    float3 filteredShadow = UnpackFromR11G11B10f(gs_cacheShadow[ShadowOffsetToLDSAdress(groupThreadId, int2(-1, -1))]);
    filteredShadow += UnpackFromR11G11B10f(gs_cacheShadow[ShadowOffsetToLDSAdress(groupThreadId, int2(0, -1))]);
    filteredShadow += UnpackFromR11G11B10f(gs_cacheShadow[ShadowOffsetToLDSAdress(groupThreadId, int2(1, -1))]);
    filteredShadow += UnpackFromR11G11B10f(gs_cacheShadow[ShadowOffsetToLDSAdress(groupThreadId, int2(-1, 0))]);
    filteredShadow += centerShadow;
    filteredShadow += UnpackFromR11G11B10f(gs_cacheShadow[ShadowOffsetToLDSAdress(groupThreadId, int2(1, 0))]);
    filteredShadow += UnpackFromR11G11B10f(gs_cacheShadow[ShadowOffsetToLDSAdress(groupThreadId, int2(-1, 1))]);
    filteredShadow += UnpackFromR11G11B10f(gs_cacheShadow[ShadowOffsetToLDSAdress(groupThreadId, int2(0, 1))]);
    filteredShadow += UnpackFromR11G11B10f(gs_cacheShadow[ShadowOffsetToLDSAdress(groupThreadId, int2(1, 1))]);

    // We have a different behavior if this is a border pixel
    float borderPixel = currentCoords.x == 0 || currentCoords.y == 0 || ((int)currentCoords.x) == (_ShadowCookieResolution - 1) || ((int)currentCoords.y) == (_ShadowCookieResolution - 1) ? 1.0 : 0.0;

    // Normalize and return the result
    _VolumetricCloudsShadowRW[currentCoords.xy] = lerp(filteredShadow * 0.1111111, centerShadow, borderPixel);
}
