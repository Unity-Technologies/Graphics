// We need only need one bounce given that we want to see the objects and then direct lighting is not done using raytracing
#pragma max_recursion_depth 31

// HDRP include
#define SHADER_TARGET 50
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Macros.hlsl"
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Common.hlsl"
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Packing.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/ShaderLibrary/ShaderVariables.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/ShaderLibrary/ShaderVariablesFunctions.hlsl"
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Sampling/Sampling.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/Material/NormalBuffer.hlsl"

#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/BSDF.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/Material/PreIntegratedFGD/PreIntegratedFGD.hlsl"
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/CommonLighting.hlsl"
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/ImageBasedLighting.hlsl"

// Raytracing includes
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/RenderPipeline/Raytracing/Shaders/ShaderVariablesRaytracing.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/RenderPipeline/Raytracing/Shaders/RaytracingIntersection.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/RenderPipeline/Raytracing/Shaders/RaytracingSampling.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/RenderPipeline/Raytracing/Shaders/RayTracingCommon.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/Lighting/ScreenSpaceLighting/ScreenSpaceLighting.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/RenderPipeline/Raytracing/Shaders/Common/AtmosphericScatteringRayTracing.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/Debug/RayCountManager.cs.hlsl"

// The target acceleration structure that we will evaluate the reflexion in
TEXTURE2D_X(_DepthTexture);

// Output structure of the reflection raytrace shader
RW_TEXTURE2D_X(float4, _IndirectDiffuseTextureRW);

[shader("miss")]
void MissShaderIndirectDiffuse(inout RayIntersection rayIntersection : SV_RayPayload)
{
    rayIntersection.color = SAMPLE_TEXTURECUBE_ARRAY_LOD(_SkyTexture, s_trilinear_clamp_sampler, rayIntersection.incidentDirection, 0.0f, 0).xyz;
    rayIntersection.t = _RaytracingRayMaxLength;
    ApplyFogAttenuation(WorldRayOrigin(), WorldRayDirection(), rayIntersection.color);
}

[shader("raygeneration")]
void RayGenIntegration()
{
    // Grab the dimensions of the current dispatch
    uint3 LaunchIndex = DispatchRaysIndex();
    uint3 LaunchDim = DispatchRaysDimensions();

    UNITY_XR_ASSIGN_VIEW_INDEX(LaunchIndex.z);

    // Compute the pixel coordinate to evaluate
    uint2 currentCoord = uint2(LaunchIndex.x, LaunchDim.y - LaunchIndex.y - 1);

    // Clear the output color texture
    _IndirectDiffuseTextureRW[COORD_TEXTURE2D_X(currentCoord)] = float4(0.0f, 0.0f, 0.0f, 0.0f);

    // Read the depth value
    float depthValue  = LOAD_TEXTURE2D_X(_DepthTexture, currentCoord).x;

    // This point is part of the background, we don't really care
    if (depthValue == UNITY_RAW_FAR_CLIP_VALUE)
        return;

    // Convert this to a world space position
    PositionInputs posInput = GetPositionInput(currentCoord, 1.0f/LaunchDim.xy, depthValue, UNITY_MATRIX_I_VP, GetWorldToViewMatrix(), 0);
    float distanceToCamera = length(posInput.positionWS);
    // The position is always in the right space.
    const float3 positionWS = posInput.positionWS;
    // Compute the incident vector on the surfaces
    const float3 viewWS = GetWorldSpaceNormalizeViewDir(positionWS);

    // Decode the world space normal
    NormalData normalData;
    DecodeFromNormalBuffer(currentCoord, normalData);

    // Variable that accumulate the radiance
    float3 finalColor = float3(0.0, 0.0, 0.0);

    // Count the number of rays that we will be traced
    if (_RayCountEnabled > 0)
    {
        uint3 counterIdx = uint3(currentCoord, INDEX_TEXTURE2D_ARRAY_X(RAYCOUNTVALUES_DIFFUSE_GI_FORWARD));
        _RayCountTexture[counterIdx] = _RayCountTexture[counterIdx] + _RaytracingNumSamples;
    }

    // Loop through the samples and add their contribution
    for (int sampleIndex = 0; sampleIndex < _RaytracingNumSamples; ++sampleIndex)
    {
        // Compute the current sample index
        int globalSampleIndex = _RaytracingFrameIndex * _RaytracingNumSamples + sampleIndex;

    	// Generate the new sample (follwing values of the sequence)
        float2 theSample;
        theSample.x = GetBNDSequenceSample(currentCoord, globalSampleIndex, 0);
        theSample.y = GetBNDSequenceSample(currentCoord, globalSampleIndex, 1);

        // Importance sample with a cosine lobe
        float3 sampleDir = SampleHemisphereCosine(theSample.x, theSample.y, normalData.normalWS);

        // Create the ray descriptor for this pixel
        RayDesc rayDescriptor;
        rayDescriptor.Origin = positionWS + normalData.normalWS * _RaytracingRayBias;
        rayDescriptor.Direction = sampleDir;
        rayDescriptor.TMin = 0.0f;
        rayDescriptor.TMax = _RaytracingRayMaxLength;

        // Create and init the RayIntersection structure for this
        RayIntersection rayIntersection;
        rayIntersection.color = float3(0.0, 0.0, 0.0);
        rayIntersection.incidentDirection = rayDescriptor.Direction;
        rayIntersection.origin = rayDescriptor.Origin;
        rayIntersection.t = -1.0f;
        rayIntersection.remainingDepth = 1;
        rayIntersection.pixelCoord = currentCoord;
        rayIntersection.sampleIndex = globalSampleIndex;

        // In order to achieve filtering for the textures, we need to compute the spread angle of the pixel
        rayIntersection.cone.spreadAngle = _RaytracingPixelSpreadAngle + roughnessToSpreadAngle(1.0);
        rayIntersection.cone.width = distanceToCamera * _RaytracingPixelSpreadAngle;

        // Evaluate the ray intersection
        TraceRay(_RaytracingAccelerationStructure, RAY_FLAG_CULL_BACK_FACING_TRIANGLES, RAYTRACINGRENDERERFLAG_GLOBAL_ILLUMINATION, 0, 1, 0, rayDescriptor, rayIntersection);

        // Contribute to the pixel
        finalColor += rayIntersection.color;
    }

   	// Normalize the value
    finalColor *= 1.0f / _RaytracingNumSamples;

    // Convert to HSV space
    finalColor = RgbToHsv(finalColor * GetCurrentExposureMultiplier());

    // Expose and clamp the final color
    finalColor.z = clamp(finalColor.z, 0.0, _RaytracingIntensityClamp);

    // Convert back to HSV space
    finalColor = HsvToRgb(finalColor);
    // We store the sampled color and the weight that shall be used for it (1.0f)
    _IndirectDiffuseTextureRW[COORD_TEXTURE2D_X(currentCoord)] = float4(finalColor, 1.0f);
}

[shader("closesthit")]
void ClosestHitMain(inout RayIntersection rayIntersection : SV_RayPayload, AttributeData attributeData : SV_IntersectionAttributes)
{
	// When we do not hit any known closest hit, that means that no shader was specified for the target object meaning either it has nothing to do in the acceleration structure or we need to add raytracing subshaders to it
	rayIntersection.color = float3(1.0, 0.0, 0.5);
}
