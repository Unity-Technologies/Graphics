// We need only need one bounce given that we want to see the objects and then direct lighting is not done using raytracing
#pragma max_recursion_depth 31

// HDRP include
#define SHADER_TARGET 50
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Macros.hlsl"
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Common.hlsl"
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Packing.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/ShaderLibrary/ShaderVariables.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/ShaderLibrary/ShaderVariablesFunctions.hlsl"
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Sampling/Sampling.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/Material/NormalBuffer.hlsl"

#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/BSDF.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/Material/PreIntegratedFGD/PreIntegratedFGD.hlsl"
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/CommonLighting.hlsl"
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/ImageBasedLighting.hlsl"

// Raytracing includes
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/RenderPipeline/Raytracing/Shaders/ShaderVariablesRaytracing.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/RenderPipeline/Raytracing/Shaders/RaytracingIntersection.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/RenderPipeline/Raytracing/Shaders/RaytracingSampling.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/RenderPipeline/Raytracing/Shaders/RayTracingCommon.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/Lighting/ScreenSpaceLighting/ScreenSpaceLighting.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/RenderPipeline/RayTracing/Shaders/Common/AtmosphericScatteringRayTracing.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/Debug/RayCountManager.cs.hlsl"

// The target acceleration structure that we will evaluate the reflexion in
TEXTURE2D_X(_DepthTexture);
TEXTURE2D_X(_SsrClearCoatMaskTexture);

// Flag value that defines if a given pixel recieves reflections or not
TEXTURE2D_X_UINT2(_StencilTexture);
int _SsrStencilBit;

// Output structure of the reflection raytrace shader
RW_TEXTURE2D_X(float4, _SsrLightingTextureRW);
RW_TEXTURE2D_X(float4, _SsrHitPointTexture);

[shader("miss")]
void MissShaderReflections(inout RayIntersection rayIntersection : SV_RayPayload)
{
    if(_RaytracingIncludeSky != 0)
    {
        rayIntersection.color = SAMPLE_TEXTURECUBE_ARRAY_LOD(_SkyTexture, s_trilinear_clamp_sampler, rayIntersection.incidentDirection, 0.0, 0).xyz;
        ApplyFogAttenuation(WorldRayOrigin(), WorldRayDirection(), rayIntersection.color);
    }
    rayIntersection.t = _RaytracingRayMaxLength;
}

[shader("raygeneration")]
void RayGenIntegration()
{
    // Grab the dimensions of the current dispatch
    uint3 LaunchIndex = DispatchRaysIndex();
    uint3 LaunchDim = DispatchRaysDimensions();

    UNITY_XR_ASSIGN_VIEW_INDEX(LaunchIndex.z);

    // Compute the pixel coordinate to evaluate
    uint2 currentCoord = uint2(LaunchIndex.x, LaunchDim.y - LaunchIndex.y - 1);

    // Clear the output color texture
    _SsrLightingTextureRW[COORD_TEXTURE2D_X(currentCoord)] = float4(0.0, 0.0, 0.0, 0.0);

    // Read the depth value
    float depthValue  = LOAD_TEXTURE2D_X(_DepthTexture, currentCoord).r;

    // This point is part of the background, we don't really care
    if (depthValue == UNITY_RAW_FAR_CLIP_VALUE)
        return;

    // Does this pixel have SSS?
    uint stencilValue = GetStencilValue(LOAD_TEXTURE2D_X(_StencilTexture, currentCoord));
    if ((stencilValue & _SsrStencilBit) == 0)
        return;

    // Convert this to a world space position
    PositionInputs posInput = GetPositionInput(currentCoord, 1.0/LaunchDim.xy, depthValue, UNITY_MATRIX_I_VP, GetWorldToViewMatrix(), 0);
    float distanceToCamera = length(posInput.positionWS);
    // Compute the incident vector on the surfaces
    const float3 viewWS = GetWorldSpaceNormalizeViewDir(posInput.positionWS);

    // Decode the world space normal
    NormalData normalData;
    DecodeFromNormalBuffer(currentCoord, normalData);
    // Override the roughness by the clearcoat value of this is a clear coat
    float4 coatMask = LOAD_TEXTURE2D_X(_SsrClearCoatMaskTexture, currentCoord);
    normalData.perceptualRoughness = HasClearCoatMask(coatMask) ? CLEAR_COAT_PERCEPTUAL_ROUGHNESS : normalData.perceptualRoughness;

    // Create the local ortho basis
    float3x3 localToWorld = GetLocalFrame(normalData.normalWS);

    // If this value is beyond the smothness that we allow, no need to compute it
    float perceptualSmoothness = PerceptualRoughnessToPerceptualSmoothness(normalData.perceptualRoughness);
    if (_RaytracingReflectionMinSmoothness > perceptualSmoothness)
        return;

    // Compute the actual roughness
    float roughness = PerceptualRoughnessToRoughness(normalData.perceptualRoughness);

    // If we only have one bounce, we don't need more than one ray to evaluate the exact signal. However, if we are going for multiple bounces, we may need more, so we cannot clamp the sample count to 1.
    int realSampleCount = _RaytracingMaxRecursion == 1 ? (normalData.perceptualRoughness < 0.01 ? 1 : _RaytracingNumSamples) : _RaytracingNumSamples;

    // Variable that accumulate the radiance
    float3 finalColor = float3(0.0, 0.0, 0.0);

    // Loop through the samples and add their contribution
    for (int sampleIndex = 0; sampleIndex < realSampleCount; ++sampleIndex)
    {
        // Compute the current sample index
        int globalSampleIndex = _RaytracingFrameIndex * realSampleCount + sampleIndex;

        // Generate the new sample (follwing values of the sequence)
        float2 sample;
        sample.x = GetBNDSequenceSample(currentCoord, globalSampleIndex, 0);
        sample.y = GetBNDSequenceSample(currentCoord, globalSampleIndex, 1);

        // Importance sample the direction using GGX
        float3 sampleDir = float3(0.0, 0.0, 0.0);
        float NdotL, NdotH, VdotH;
        SampleGGXDir(sample, viewWS, localToWorld, roughness, sampleDir, NdotL, NdotH, VdotH);

        // If the sample is under the surface
        if (dot(sampleDir, normalData.normalWS) <= 0.0)
            continue;

        // Make sure the new ray is taken into account in the ray counters
        if (_RayCountEnabled > 0)
        {
            uint3 counterIdx = uint3(currentCoord, INDEX_TEXTURE2D_ARRAY_X(RAYCOUNTVALUES_REFLECTION_FORWARD));
            _RayCountTexture[counterIdx] = _RayCountTexture[counterIdx] + 1;
        }

        // Create the ray descriptor for this pixel
        RayDesc rayDescriptor;
        rayDescriptor.Origin = posInput.positionWS + normalData.normalWS * _RaytracingRayBias;
        rayDescriptor.Direction = sampleDir;
        rayDescriptor.TMin = 0.0;
        rayDescriptor.TMax = _RaytracingRayMaxLength;

        // Create and init the RayIntersection structure for this
        RayIntersection rayIntersection;
        rayIntersection.color = float3(0.0, 0.0, 0.0);
        rayIntersection.incidentDirection = rayDescriptor.Direction;
        rayIntersection.origin = rayDescriptor.Origin;
        rayIntersection.t = -1.0;
        rayIntersection.remainingDepth = 1;
        rayIntersection.sampleIndex = globalSampleIndex;
        rayIntersection.pixelCoord = currentCoord;

        // In order to achieve filtering for the textures, we need to compute the spread angle of the pixel
        rayIntersection.cone.spreadAngle = _RaytracingPixelSpreadAngle + roughnessToSpreadAngle(roughness);
        rayIntersection.cone.width = distanceToCamera * _RaytracingPixelSpreadAngle;

        // Evaluate the ray intersection
        TraceRay(_RaytracingAccelerationStructure, RAY_FLAG_CULL_BACK_FACING_TRIANGLES, RAYTRACINGRENDERERFLAG_REFLECTION, 0, 1, 0, rayDescriptor, rayIntersection);

        // Contribute to the pixel
        finalColor += rayIntersection.color;
    }

   	// Normalize the value
    finalColor *= 1.0 / realSampleCount;

    // Expose and clamp the final color
    finalColor = clamp(finalColor * GetCurrentExposureMultiplier(), 0.0, _RaytracingIntensityClamp) * GetInverseCurrentExposureMultiplier();

    // We also need to compute the fade factor for this sample
    float weightValue = _RaytracingReflectionSmoothnessFadeStart == _RaytracingReflectionMinSmoothness ? 1.0 : saturate((perceptualSmoothness - _RaytracingReflectionMinSmoothness) / (_RaytracingReflectionSmoothnessFadeStart -_RaytracingReflectionMinSmoothness));

    // We store the sampled color and the weight that shall be used for it (1.0)
    _SsrLightingTextureRW[COORD_TEXTURE2D_X(currentCoord)] = float4(finalColor, weightValue);
}

[shader("raygeneration")]
void RayGenIntegrationTransparent()
{
    // Grab the dimensions of the current dispatch
    uint3 LaunchIndex = DispatchRaysIndex();
    uint3 LaunchDim = DispatchRaysDimensions();

    UNITY_XR_ASSIGN_VIEW_INDEX(LaunchIndex.z);

    // Compute the pixel coordinate to evaluate
    uint2 currentCoord = uint2(LaunchIndex.x, LaunchDim.y - LaunchIndex.y - 1);

    // Clear the output color texture
    _SsrLightingTextureRW[COORD_TEXTURE2D_X(currentCoord)] = float4(0.0, 0.0, 0.0, 0.0);

    // Read the depth value
    float depthValue  = LOAD_TEXTURE2D_X(_DepthTexture, currentCoord).r;

    // This point is part of the background, we don't really care
    if (depthValue == UNITY_RAW_FAR_CLIP_VALUE)
        return;

    // Does this pixel have SSS?
    uint stencilValue = GetStencilValue(LOAD_TEXTURE2D_X(_StencilTexture, currentCoord));
    if ((stencilValue & _SsrStencilBit) == 0)
        return;

    // Convert this to a world space position
    PositionInputs posInput = GetPositionInput(currentCoord, 1.0/LaunchDim.xy, depthValue, UNITY_MATRIX_I_VP, GetWorldToViewMatrix(), 0);
    float distanceToCamera = length(posInput.positionWS);

    float3 positionWS = posInput.positionWS;

    // Compute the incident vector on the surfaces
    const float3 viewWS = GetWorldSpaceNormalizeViewDir(posInput.positionWS);

    // Decode the world space normal
    NormalData normalData;
    DecodeFromNormalBuffer(currentCoord, normalData);

    // If this value is beyond the smothness that we allow, no need to compute it
    float perceptualSmoothness = PerceptualRoughnessToPerceptualSmoothness(normalData.perceptualRoughness);
    if (_RaytracingReflectionMinSmoothness > perceptualSmoothness)
        return;

    // Compute the reflected direction
    float3 reflectionDir = reflect(-viewWS, normalData.normalWS);

    // Make sure the new ray is taken into account in the ray counters
    if (_RayCountEnabled > 0)
    {
        uint3 counterIdx = uint3(currentCoord, INDEX_TEXTURE2D_ARRAY_X(RAYCOUNTVALUES_REFLECTION_FORWARD));
        _RayCountTexture[counterIdx] = _RayCountTexture[counterIdx] + 1;
    }

    // Create the ray descriptor for this pixel
    RayDesc rayDescriptor;
    rayDescriptor.Origin = positionWS + normalData.normalWS * _RaytracingRayBias;
    rayDescriptor.Direction = reflectionDir;
    rayDescriptor.TMin = 0.0;
    rayDescriptor.TMax = _RaytracingRayMaxLength;

    // Create and init the RayIntersection structure for this
    RayIntersection rayIntersection;
    rayIntersection.color = float3(0.0, 0.0, 0.0);
    rayIntersection.incidentDirection = rayDescriptor.Direction;
    rayIntersection.origin = rayDescriptor.Origin;
    rayIntersection.t = -1.0;
    rayIntersection.remainingDepth = 1;
    rayIntersection.sampleIndex = 0;
    rayIntersection.pixelCoord = currentCoord;

    // In order to achieve filtering for the textures, we need to compute the spread angle of the pixel
    rayIntersection.cone.spreadAngle = _RaytracingPixelSpreadAngle;
    rayIntersection.cone.width = distanceToCamera * _RaytracingPixelSpreadAngle;

    // Evaluate the ray intersection
    TraceRay(_RaytracingAccelerationStructure, RAY_FLAG_CULL_BACK_FACING_TRIANGLES, RAYTRACINGRENDERERFLAG_REFLECTION, 0, 1, 0, rayDescriptor, rayIntersection);

    // Expose and clamp the final color
    float3 finalColor = clamp(rayIntersection.color * GetCurrentExposureMultiplier(), 0.0, _RaytracingIntensityClamp) * GetInverseCurrentExposureMultiplier();

    // We store the sampled color and the weight that shall be used for it (1.0)
    _SsrLightingTextureRW[COORD_TEXTURE2D_X(currentCoord)] = float4(finalColor, 1.0);
}

[shader("closesthit")]
void ClosestHitMain(inout RayIntersection rayIntersection : SV_RayPayload, AttributeData attributeData : SV_IntersectionAttributes)
{
	// When we do not hit any known closest hit, that means that no shader was specified for the target object meaning either it has nothing to do in the acceleration structure or we need to add raytracing subshaders to it
	rayIntersection.color = float3(1.0, 0.0, 0.5);
}
